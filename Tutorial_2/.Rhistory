install.packages("plyr", dependencies = TRUE)
install.packages("dplyr", dependencies = TRUE)
install.packages("reshape2")
p
install.packages("sqldf")
install.packages("ggplot2")
install.packages("ggmap")
install.packages("GGally")
install.packages("gcookbook")
install.packages("scales")
install.packages("visualize")
install.packages("EnvStats")
install.packages("rMR")
install.packages("sampling")
install.packages("mice")
install.packages("pwr")
install.packages("survival")
install.packages("FrF2")
install.packages("DoE.base")
install.packages("MASS")
install.packages("fitdistrplus")
install.packages("car")
install.packages("predictmeans")
install.packages("caret")
install.packages("e1071")
install.packages("IpSolve")
install.packages("lpSolve")
install.packages("pracma")
install.packages("SparseM")
remove.packages("Matrix", lib="C:/Program Files/R/R-3.5.1/library")
remove.packages("MatrixModels", lib="~/R/win-library/3.5")
remove.packages("Matrix", lib="C:/Program Files/R/R-3.5.1/library")
remove.packages("Matrix", lib="C:/Program Files/R/R-3.5.1/library")
remove.packages("Matrix", lib="C:/Program Files/R/R-3.5.1/library")
library("Matrix", lib.loc="C:/Program Files/R/R-3.5.1/library")
remove.packages("Matrix", lib="C:/Program Files/R/R-3.5.1/library")
install.packages("MatrixModels")
install.packages("alr3")
install.packages("caTools")
install.packages("leaps")
install.packages("party")
install.packages("party")
install.packages("rpart.plot")
install.packages("tree")
install.packages("lars")
install.packages("pls")
install.packages("randomForest")
x=1
class(x)
x='1'
class(x)
Boston[1:6]
library("MASS", lib.loc="~/R/win-library/3.5")
library("MASS", lib.loc="C:/Program Files/R/R-3.5.1/library")
Boston[1:6]
fix(Boston)
Boston[1,1]
Boston[1,0]
Boston[0,0]
fix(Boston)
c(1,'k')
c(1,2)
x=matrix(c(1,2,1,0),2,2)
x
x%*%x
x*x
x
a=solve(x)
a
a*x
x*a
x
a=solve(x)
a
a*x
x1=matrix(c(1,2,1,0),2,2)
x1
a=solve(x1)
a
a*x1
x1*a
x=matrix(c(1,1,1,1,1,1,1,1,1),3,3)
x
a=solve(x)
x=matrix(c(1,0,0,1),2,2)
x
a=solve(x)
a
x=matrix(c(0,1,1,0),2,2)
a=solve(x)
a
a*x
rnorm(1)
rnorm(12)
plot(rnorm(100))
plot(rnorm(1000))
plot(rnorm(10000))
x=matrix(c(1,2,1,0),2,2)
x
a=solve(x)
a
a*x
qr.a*x
qr.solve(x)*x
a=rnorm(1000)
plot(a)
Boston
fix(Boston)
Boston[1:10]
Boston[1:10,]
lm(medv ~ lstat)
attach(Boston)
lm(medv ~ lstat)
summary(lm(medv ~ lstat))
install.packages("MASS")
library(MASS)
library(ISLR)
fix(BOSTOn)
fix(BOSTOn)
fix(Boston)
fix(Boston) #Boston Dataset
# medv - median house values
# rm - avg no. of rooms per house
# age - avg age of house
# lstat -  percent of households with low socioeconomic status
names(Boston)
names(Boston)
setwd("G:/IIT_MADRAS_DD/Semesters/7th sem (UQ)/ECON2333 (Big Data and Machine learning in Finance and economics)/Tutorial_Sol/Tutorial_2")
library(MASS)
library(ISLR)
fix(Boston) #Boston Dataset
# medv - median house values
# rm - avg no. of rooms per house
# age - avg age of house
# lstat -  percent of households with low socioeconomic status
names(Boston)
attach(Boston)
lm.fit = lm(medv~lstat) #lm.fit = lm(medv~lstat,data=Boston)
lm.fit
plot(medv,lstat)
plot(lm.fit)
plot(medv,lstat)
lm.fit
summary(lm.fit)
names(lm.fit)
fix(lm.fit)
names(lm.fit)
coef(lm.fit)
#In order to obtain a conﬁdence interval for the coeﬃcient estimates, we can use the confint() command
confint(lm.fit)
names(lm.fit)
coef(lm.fit)
#In order to obtain a conﬁdence interval for the coeﬃcient estimates, we can use the confint() command
confint(lm.fit)
#In order to obtain a conﬁdence interval for the coeﬃcient estimates, we can use the confint() command
confint (lm.fit)
predict (lm.fit ,data.frame(lstat=c(5,10,15)), interval="confidence")
#In order to obtain a conﬁdence interval for the coeﬃcient estimates, we can use the confint() command
confint(lm.fit)
rm(list=ls())
library(MASS)
fix(Boston)
attach(Boston)
lm(medv~lstat)
lm.fit=lm(medv~lstat)
summary(lm.fit)
names(lm.fit)
lm.fit$coefficients
confint(lm.fit)
setwd("G:/IIT_MADRAS_DD/Semesters/7th sem (UQ)/ECON2333 (Big Data and Machine learning in Finance and economics)/Tutorial_Sol/Tutorial_2")
library(MASS)
library(ISLR)
fix(Boston) #Boston Dataset
# medv - median house values
# rm - avg no. of rooms per house
# age - avg age of house
# lstat -  percent of households with low socioeconomic status
names(Boston)
attach(Boston)
lm.fit = lm(medv~lstat) #lm.fit = lm(medv~lstat,data=Boston)
lm.fit
summary(lm.fit)
names(lm.fit)
coef(lm.fit)
#In order to obtain a conﬁdence interval for the coeﬃcient estimates, we can use the confint() command
confint(lm.fit)
predict (lm.fit ,data.frame(lstat=c(5,10,15)), interval="confidence")
predict (lm.fit ,data.frame(lstat=c(5,10,15)), interval="prediction")
plot(lstat,medv)
abline(lm.fit)
abline(lm.fit, col="Red")
abline(lm.fit, col="Red", lwd=3)
abline(lm.fit, col="Red", lwd=3, pch=20)
abline(lm.fit, col="Red", lwd=3, pch=+)
abline(lm.fit, col="Red", lwd=3, pch="+")
abline(lm.fit, col="Red", lwd=3, pch=1:20)
par(mfrow=c(2,2))
plot(lm.fit)
plot(predict (lm.fit), residuals (lm.fit))
plot(hatvalues (lm.fit))
which.max(hatvalues (lm.fit))
lm.fit=lm(medv∼lstat+age,data=Boston)
lm.fit
summary(lm.fit)
#The Boston data set contains 13 variables, and so it would be cumbersome
#to have to type all of these in order to perform a regression using all of
#the predictors. Instead, we can use the following short-hand:
lm.fit=lm(medv∼.,data=Boston)
lm.fit
summary(lm.fit)
summary(lm.fit)$sigma
library(car)
vif(lm.fit)
lm.fit1 = lm(medv~.-age, data=Boston) # The following syntax results in a regression using all predictors except age.
summary(lm.fit1)
lm.fit
lm.fit1
lm(medv~lstat*age, data=Boston)
lm(medv~lstat:age, data=Boston)
lm(medv~lstat+age+lstat:age, data=Boston)
summary(lm(medv~lstat*age, data=Boston))
lm.fit2 = lm(medv~lstat+I(lstat^2))
lm.fit2
plot(lm.fit2)
plot(lm.fit)
lm.fit = lm(medv~lstat)
anova(lm.fit, lm.fit2)
par(mfrow=c(2,2))
plot(lm.fit2)
lm.fit5=lm(medv∼poly(lstat,5))
lm.fit5
n = 100
a = 2.1
b = -0.9
x = runif(n)
#1
rm(list=ls())
n = 100
a = 2.1
b = -0.9
x = runif(n)
y = b*x + rnorm(n, mean=a)
x
y
lm.fit = lm(y~x)
lm.fit
n = 1000
a = 2.1
b = -0.9
x = runif(n)
y = b*x + rnorm(n, mean=a)
lm.fit = lm(y~x)
lm.fit
rm(list=ls())
setwd = "G:/IIT_MADRAS_DD/Semesters/7th sem (UQ)/ECON2333 (Big Data and Machine learning in Finance and economics)/Tutorial_Sol/Tutorial_3"
#*****************3.6.6******************#
#Qualitative Predictors
library(ISLR)
fix(Carseats)
names(Carseats)
lm.fit = lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)
lm.fit
summary(lm.fit)
attach(Carseats)
contrasts (ShelveLoc )
?contrats
?contrasts
LoadLibraries = function(){
library(ISLR)
library(MASS)
print("The libraries have been loaded")
}
LoadLibraries()
x = read.csv("MC1.csv")
rm(list=ls())
setwd = "G:/IIT_MADRAS_DD/Semesters/7th sem (UQ)/ECON2333 (Big Data and Machine learning in Finance and economics)/Tutorial_Sol/Tutorial_3"
x = read.csv("MC1.csv")
x = read.csv(file="MC1.csv", header=TRUE, sep=",")
x = read.csv(file="MC1.csv", header=TRUE, na.string="?")
x = read.csv(file="MC1.csv", header=TRUE)
x = read.csv(file="MC1.csv")
#***************Exercise-2*******************#
setwd = "G:/IIT_MADRAS_DD/Semesters/7th sem (UQ)/ECON2333 (Big Data and Machine learning in Finance and economics)/Tutorial_Sol/Tutorial_3"
x = read.csv(file="MC1.csv")
setwd = "G:/IIT_MADRAS_DD/Semesters/7th sem (UQ)/ECON2333 (Big Data and Machine learning in Finance and economics)/Tutorial_Sol/Tutorial_3"
x = read.csv(file="MC1.csv")
# PART 1
setwd = "G:/IIT_MADRAS_DD/Semesters/7th sem (UQ)/ECON2333 (Big Data and Machine learning in Finance and economics)/Tutorial_Sol/Tutorial_3"
x = read.csv("MC1.csv") #MC1 dataset
exp(9)
# Y = exp(beta)*X + epsilon
beta = 0.6
rm(list=ls())
setwd = "G:/IIT_MADRAS_DD/Semesters/7th sem (UQ)/ECON2333 (Big Data and Machine learning in Finance and economics)/Assignment_1"
# Y = exp(beta)*X + epsilon
beta = 0.6
n = 1000
X = rnorm(n)
epsilon = rnorm(n)
X==epsilon
# (1)
Y = exp(beta)*X + epsilon
length(Y)
lm.fit = lm(Y~X)
lm.fit
lm.fit = lm(Y~X +epsilon)
lm.fit
lm2.fit = lm(Y~X+I(X^2)) #Linear Regression
lm2.fit
I(9^2)
lm3.fit = lm(Y~poly(X,3)) #Linear Regression
lm3.fit
lm2.fit = lm(Y~poly(X,2) #Linear Regression
lm3.fit = lm(Y~poly(X,3)) #Linear Regression
lm2.fit = lm(Y~poly(X,2)) #Linear Regression
lm2.fit
lm3.fit = lm(Y~poly(X,3)) #Linear Regression
lm3.fit
plot(Y,X)
plot(lm.fit1)
plot(lm1.fit)
lm1.fit = lm(Y~X) #Linear Regression
lm1.fit
plot(lm1.fit)
par(mfrow=c(2,2))
plot(lm1.fit)
par(mfrow=c(2,2))
plot(lm2.fit)
par(mfrow=c(2,2))
plot(lm3.fit)
par(mfrow=c(2,2))
plot(lm2.fit)
par(mfrow=c(2,2))
plot(lm1.fit)
lm2.fit = lm(Y~poly(X,2)) #Linear Regression
lm2.fit
par(mfrow=c(2,2))
plot(lm2.fit)
lm3.fit = lm(Y~poly(X,3)) #Linear Regression
lm3.fit
par(mfrow=c(2,2))
plot(lm3.fit)
par(mfrow=c(2,2))
plot(lm1.fit)
plot(X,Y)
abline(lm1.fit, col="Red", lwd=3)
abline(lm2.fit, col="Green", lwd=4)
abline(lm2.fit, col="Green", lwd=3)
abline(lm3.fit, col="Yellow", lwd=3)
abline(lm3.fit, col="Yellow", lwd=2)
lm1.fit = lm(Y~X) #Linear Regression
lm1.fit
par(mfrow=c(2,2))
plot(lm1.fit)
lm1.fit = lm(Y~X) #Linear Regression
lm1.fit
par(mfrow=c(2,2))
plot(lm1.fit)
plot(lm1.fit)
plot(lm1.fit)
plot(lm1.fit)
rm(list=ls())
setwd = "G:/IIT_MADRAS_DD/Semesters/7th sem (UQ)/ECON2333 (Big Data and Machine learning in Finance and economics)/Assignment_1"
# Y = exp(beta)*X + epsilon
beta = 0.6
n = 1000
X = rnorm(n)
epsilon = rnorm(n)
# (1)
Y = exp(beta)*X + epsilon
# (d)
plot(X,Y)
abline(lm1.fit, col="Red", lwd=3)
abline(lm2.fit, col="Green", lwd=3)
lm1.fit = lm(Y~X) #Linear Regression
lm1.fit
abline(lm1.fit, col="Red")
par(mfrow=c(2,2))
plot(lm1.fit)
lm2.fit = lm(Y~poly(X,2)) #Quadratic Regression
lm2.fit
par(mfrow=c(2,2))
plot(lm2.fit)
lm3.fit = lm(Y~poly(X,3)) #Cubic Regression
lm3.fit
par(mfrow=c(2,2))
plot(lm3.fit)
# (d)
plot(X,Y)
abline(lm1.fit, col="Red", lwd=3)
abline(lm2.fit, col="Green", lwd=3)
abline(lm3.fit, col="Yellow", lwd=2)
par(mfrow=c(2,2))
plot(X,Y)
plot(lm1.fit)
# (d)
plot(X,Y)
# (d)
plot(X,Y)
abline(lm1.fit, col="Red", lwd=3)
lines(smooth.spline(X), predict(lm2.fit), col="blue", lwd=3)
length(X)
length(Y)
length(lm2.fit)
lm2.fit
# (d)
plot(X,Y)
abline(lm1.fit, col="Red", lwd=3)
lines(smooth.spline(X), predict(lm2.fit), col="blue", lwd=3)
lines(X, predict(lm2.fit), col="blue", lwd=3)
lines(X, predict(lm2.fit), col="blue", lwd=2)
lines(X, predict(lm3.fit), col="green", lwd=2)
# (d)
plot(X,Y)
abline(lm1.fit, col="Red", lwd=3)
lines(X, predict(lm2.fit), col="blue", lwd=2)
plot(X, predict(lm2.fit), col="green")
# (d)
plot(X,Y)
abline(lm1.fit, col="Red", lwd=3)
lines(X, predict(lm2.fit), col="blue", lwd=2)
points(X, predict(lm2.fit), col="blue", lwd=2)
# (d)
plot(X,Y)
abline(lm1.fit, col="Red", lwd=3)
points(X, predict(lm2.fit), col="blue", lwd=2)
# (d)
plot(X,Y)
abline(lm1.fit, col="Red", lwd=3)
points(X, predict(lm2.fit), col="blue", lwd=1)
points(X, predict(lm3.fit), col="blue", lwd=1)
# (d)
plot(X,Y)
abline(lm1.fit, col="Red", lwd=1)
points(X, predict(lm2.fit), col="blue", lwd=1)
points(X, predict(lm3.fit), col="green", lwd=1)
